{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3acd6024",
   "metadata": {},
   "source": [
    "### üßπ Data Cleaning: Explained Simply with a Real Example from Sports\n",
    "\n",
    "**Data cleaning** is the process of detecting and correcting (or removing) inaccurate, incomplete, inconsistent, or irrelevant data from a dataset. It‚Äôs a key step before analysis or building models, because messy data can lead to wrong conclusions.\n",
    "\n",
    "Let‚Äôs walk through this with a **real-world-inspired example in soccer**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öΩÔ∏è Real-World Example: Soccer Player Performance Data\n",
    "\n",
    "Imagine you're analyzing performance data from a soccer league to find top-performing players. The dataset includes fields like:\n",
    "\n",
    "* Player Name\n",
    "* Team\n",
    "* Goals\n",
    "* Assists\n",
    "* Minutes Played\n",
    "* Yellow Cards\n",
    "* Red Cards\n",
    "* Match Date\n",
    "\n",
    "### üõ†Ô∏è Step-by-Step Data Cleaning Process\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Remove Duplicates**\n",
    "\n",
    "**Problem:** The same match data might have been logged twice.\n",
    "\n",
    "\n",
    "Before:\n",
    "| Player     | Team     | Goals | Match Date |\n",
    "|------------|----------|-------|------------|\n",
    "| Lionel M.  | PSG      | 2     | 2021-10-19 |\n",
    "| Lionel M.  | PSG      | 2     | 2021-10-19 |\n",
    "\n",
    "Action: Remove the duplicate row.\n",
    "\n",
    "After:\n",
    "| Player     | Team     | Goals | Match Date |\n",
    "|------------|----------|-------|------------|\n",
    "| Lionel M.  | PSG      | 2     | 2021-10-19 |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Handle Missing Values**\n",
    "\n",
    "**Problem:** Some rows may have missing data.\n",
    "\n",
    "\n",
    "Before:\n",
    "| Player     | Goals | Assists |\n",
    "|------------|-------|---------|\n",
    "| Neymar     | 1     | 2       |\n",
    "| Mbapp√©     |       | 1       |\n",
    "\n",
    "Action:\n",
    "- If \"Goals\" is missing, fill with 0 (or use the player‚Äôs average).\n",
    "- Or remove the row if too many important fields are missing.\n",
    "\n",
    "After:\n",
    "| Player     | Goals | Assists |\n",
    "|------------|-------|---------|\n",
    "| Neymar     | 1     | 2       |\n",
    "| Mbapp√©     | 0     | 1       |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Fix Inconsistent Formatting**\n",
    "\n",
    "**Problem:** Team names or player names are written inconsistently.\n",
    "\n",
    "\n",
    "Before:\n",
    "| Player     | Team         |\n",
    "|------------|--------------|\n",
    "| Messi      | FC Barcelona |\n",
    "| MESSI      | barcelona fc |\n",
    "\n",
    "Action:\n",
    "- Standardize to \"FC Barcelona\"\n",
    "- Capitalize names consistently\n",
    "\n",
    "After:\n",
    "| Player     | Team         |\n",
    "|------------|--------------|\n",
    "| Lionel Messi | FC Barcelona |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Correct Data Types**\n",
    "\n",
    "**Problem:** Numbers are stored as text, or dates are in the wrong format.\n",
    "\n",
    "\n",
    "Before:\n",
    "| Goals | Match Date   |\n",
    "|-------|--------------|\n",
    "| \"3\"   | \"19-10-2021\" |\n",
    "\n",
    "Action:\n",
    "- Convert \"3\" from string to integer\n",
    "- Change \"19-10-2021\" to `2025-05-01` (ISO date format)\n",
    "\n",
    "After:\n",
    "| Goals | Match Date |\n",
    "|-------|------------|\n",
    "| 3     | 2021-10-19 |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Outlier Detection**\n",
    "\n",
    "**Problem:** A player is listed as having scored 15 goals in one match.\n",
    "\n",
    "Before:\n",
    "| Player  | Goals |\n",
    "|---------|-------|\n",
    "| PlayerX | 15    |\n",
    "\n",
    "Action:\n",
    "- Investigate: Is it a typo? Maybe it should be \"1.5\" or \"5\"?\n",
    "- Confirm with match logs. If wrong, correct it.\n",
    "\n",
    "After:\n",
    "| Player  | Goals |\n",
    "|---------|-------|\n",
    "| PlayerX | 5     |\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Remove Irrelevant Data**\n",
    "\n",
    "**Problem:** The dataset includes columns like ‚ÄúFan Attendance Emoji‚Äù or empty ‚ÄúNotes‚Äù.\n",
    "\n",
    "Action:\n",
    "\n",
    "* Drop columns that aren't needed for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Clean Data Ready for Analysis\n",
    "\n",
    "After cleaning, your dataset is consistent, complete, and reliable. Now you can:\n",
    "\n",
    "* Rank top scorers\n",
    "* Compare team performance\n",
    "* Build machine learning models to predict player value or injury risk\n",
    "\n",
    "---\n",
    "### Summary\n",
    "\n",
    "| Step               | Purpose                     |\n",
    "| ------------------ | --------------------------- |\n",
    "| Remove Duplicates  | Avoid double-counting       |\n",
    "| Fill Missing Data  | Improve completeness        |\n",
    "| Standardize Format | Ensure consistency          |\n",
    "| Fix Data Types     | Enable correct computations |\n",
    "| Handle Outliers    | Maintain accuracy           |\n",
    "| Drop Irrelevant    | Keep only useful data       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Day 4: Data Cleaning Essentials\n",
    "# Author: David Caleb Chaparro Orozco\n",
    "# Topic: Handling Missing Values, Duplicates, and Data Consistency using the Titanic Dataset\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Style setting\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b194c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = sns.load_dataset('titanic')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea5a3d",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39718196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a overview of the dataset\n",
    "def overview(data):\n",
    "    print(\"=\".center(50,\"=\"))\n",
    "    # Print the shape of the dataset to see how many rows and columns it has.\n",
    "    print(f\"\\nTitanic Dataset. Overview\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    print(\"=\".center(50,\"=\"))\n",
    "\n",
    "    # Display Index, Columns, and Data Types\n",
    "    print(\"Information about the features:\")\n",
    "    print(data.info())\n",
    "    print(\"=\".center(50,\"=\"))\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"Basic statistics check:\")\n",
    "    print(data.describe())\n",
    "    print(\"=\".center(50,\"=\"))\n",
    "\n",
    "    # I always run this part to understand the unique values in each column.\n",
    "    # It helps me get a sense of the data, especially which features are categorical or have low variability.\n",
    "    print(\"Checking the number of unique values:\")\n",
    "    unique_counts = {}\n",
    "    for column in data.columns:\n",
    "        unique_counts[column] = data[column].nunique()\n",
    "    unique_data = pd.DataFrame(unique_counts, index=[\"Unique Count\"]).transpose()\n",
    "    print(unique_data)\n",
    "    print(\"=\".center(50, \"=\"))\n",
    "\n",
    "    # Check for Missing Values\n",
    "    print(\"Check for missing values:\")\n",
    "    print(data.isnull().sum())\n",
    "overview(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a33b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names of the dataset\n",
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa4e44",
   "metadata": {},
   "source": [
    "## 1. Removes Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ae54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Checking for Duplicates\n",
    "print(\"\\nSTEP 1: Checking for Duplicates\")\n",
    "print(\"Number of duplicate rows before:\", data.duplicated().sum())\n",
    "\n",
    "\"\"\"\n",
    "WHY THIS MATTERS:\n",
    "Duplicate rows can skew our analysis by giving extra weight to repeated observations.\n",
    "In the Titanic dataset, duplicates might represent:\n",
    "- Multiple bookings for the same passenger (unlikely)\n",
    "- Data entry errors\n",
    "- System glitches during data collection\n",
    "\"\"\"\n",
    "\n",
    "# We'll drop exact duplicates but keep potential similar records (like family members)\n",
    "data.drop_duplicates(inplace=True)\n",
    "print(\"Number of duplicate rows after:\", data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7eb769",
   "metadata": {},
   "source": [
    "## 2. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb520f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Handling Missing Values\n",
    "print(\"\\nSTEP 2: Handling Missing Values\")\n",
    "\"\"\"\n",
    "APPROACH FOR MISSING DATA:\n",
    "We'll handle missing values based on:\n",
    "1. Percentage of missingness\n",
    "2. Importance of the feature\n",
    "3. Possibility of reasonable imputation\n",
    "\"\"\"\n",
    "\n",
    "# Age: Significant missing values (177/891), we'll impute with median by passenger class\n",
    "print(\"\\nAge missing values before:\", data['age'].isnull().sum())\n",
    "\"\"\"\n",
    "STRATEGY FOR AGE:\n",
    "- Too important to drop\n",
    "- We'll impute with median by passenger class and demographic group\n",
    "    (men/women/children in 1st/2nd/3rd class had different age distributions)\n",
    "\"\"\"\n",
    "data['age'] = data.groupby(['pclass', 'who'])['age'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "print(\"Age missing values after:\", data['age'].isnull().sum())\n",
    "\n",
    "# Deck: Too many missing values (688/891), we'll drop this column as it's mostly empty\n",
    "print(\"\\nDropping 'deck' column due to excessive missing values (77% missing)\")\n",
    "\"\"\"\n",
    "WHY DROP DECK:\n",
    "- Over 3/4 of values missing\n",
    "- Not critical for survival analysis\n",
    "- Even if we impute, results would be unreliable\n",
    "\"\"\"\n",
    "data.drop('deck', axis=1, inplace=True)\n",
    "\n",
    "# Embarked/Embark_town: Only 2 missing values, we'll fill with the most common port\n",
    "print(\"\\nEmbarked missing values before:\", data['embarked'].isnull().sum())\n",
    "\"\"\"\n",
    "STRATEGY FOR EMBARKED:\n",
    "- Only 2 missing values\n",
    "- We'll use the most common port (mode)\n",
    "- Southampton was the most frequent departure point\n",
    "\"\"\"\n",
    "most_common_port = data['embarked'].mode()[0]\n",
    "data['embarked'] = data['embarked'].fillna(most_common_port)\n",
    "data['embark_town'] = data['embark_town'].fillna(most_common_port)\n",
    "print(\"Embarked missing values after:\", data['embarked'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6871a54",
   "metadata": {},
   "source": [
    "## 3. Fixing Inconsistent Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fixing Inconsistent Formatting\n",
    "print(\"\\nSTEP 3: Standardizing Formats\")\n",
    "\n",
    "print(\"\"\"\n",
    "COMMON ISSUES IN TITANIC DATA:\n",
    "- 'embark_town' vs 'embarked' (Cherbourg vs C)\n",
    "- 'sex' vs 'who' (male vs man)\n",
    "- 'alive' vs 'survived' (yes/no vs 1/0)\n",
    "\"\"\")\n",
    "\n",
    "# Standardize categorical columns\n",
    "\n",
    "# Southampton not SOUTHAMPTON\n",
    "data['embark_town'] = data['embark_town'].str.title()  \n",
    "# Man vs man consistency\n",
    "data['who'] = data['who'].str.lower()  \n",
    "\n",
    "print(\"\\nStandardizing 'embark_town' and 'who' columns:\")\n",
    "print(\"Unique embark_town values:\", data[\"embark_town\"].unique())\n",
    "print(\"Unique who values:\", data[\"who\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0b5be",
   "metadata": {},
   "source": [
    "## 4. Correcting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Correcting Data Types\n",
    "print(\"\\nSTEP 4: CORRECTING DATA TYPES\")\n",
    "\n",
    "print(\"\"\"\n",
    "TYPE ISSUES FOUND:\n",
    "- 'pclass' is numeric but represents categories (1st, 2nd, 3rd class)\n",
    "- 'survived' is int but could be boolean\n",
    "\"\"\")\n",
    "\n",
    "# Convert pclass to object\n",
    "data['pclass'] = data['pclass'].astype('object')\n",
    "\n",
    "# Convert survived to boolean (optional, kept as int for analysis)\n",
    "# data['survived'] = data['survived'].astype(bool)\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d811c",
   "metadata": {},
   "source": [
    "## 5. Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4704e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Handling Outliers\n",
    "print(\"\\nSTEP 5: Checking for Outlier\")\n",
    "\n",
    "\"\"\"\n",
    "POTENTIAL OUTLIERS:\n",
    "- Age: 0.42 to 80 (validate infants and elderly)\n",
    "- Fare: $0 to $512 (validate extreme values)\n",
    "\"\"\"\n",
    "\n",
    "# Check age distribution\n",
    "print(\"\\nAge range:\", data['age'].min(), \"to\", data['age'].max())\n",
    "# All ages are plausible (infants to elderly)\n",
    "\n",
    "# Check fare distribution\n",
    "print(\"Fare range:\", data['fare'].min(), \"to\", data['fare'].max())\n",
    "\n",
    "print(\"\"\"\n",
    "NOTE ABOUT FARES:\n",
    "- $0 fares might represent crew (but Titanic dataset is passengers only)\n",
    "- $512 is extremely high but plausible for luxury suites\n",
    "- We'll keep all fares as they represent real pricing tiers\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d51e4",
   "metadata": {},
   "source": [
    "## 6. Removing Irrelevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488cad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Removing Irrelevant Data\n",
    "print(\"\\nSTEP 6: Removing Irrelevant Columns\")\n",
    "\n",
    "print(\"\"\"\\nCOLUMNS WE'LL KEEP:\n",
    "All columns are relevant for Titanic analysis, but we:\n",
    "- Already dropped 'deck' due to missingness\n",
    "- Might drop one of redundant columns later\n",
    "\"\"\")\n",
    "\n",
    "# Example of dropping truly irrelevant columns (if they existed)\n",
    "# data = data.drop(['unnecessary_column'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ffa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Data Quality Check\n",
    "print(\"\\nFinal Data Quality REPORT\")\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "print(\"\\nDataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d2276",
   "metadata": {},
   "source": [
    "## Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('outputs/titanic_cleaned.csv', index=False)\n",
    "print(\"\\nCleaned dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6e471",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8e9a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Titanic Dataset Overview\n",
      "Shape: (891, 15)\n",
      "==================================================\n",
      "Information about the features:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n",
      "==================================================\n",
      "Basic statistics check:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "==================================================\n",
      "\n",
      "Checking the number of unique values:\n",
      "             Unique Count\n",
      "survived                2\n",
      "pclass                  3\n",
      "sex                     2\n",
      "age                    88\n",
      "sibsp                   7\n",
      "parch                   7\n",
      "fare                  248\n",
      "embarked                3\n",
      "class                   3\n",
      "who                     3\n",
      "adult_male              2\n",
      "deck                    7\n",
      "embark_town             3\n",
      "alive                   2\n",
      "alone                   2\n",
      "\n",
      "Check for missing values:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "==================================================\n",
      "\n",
      "STEP 1: Checking for Duplicates\n",
      "Number of duplicate rows before: 107\n",
      "Number of duplicate rows after: 0\n",
      "==================================================\n",
      "\n",
      "STEP 2: Handling Missing Values\n",
      "\n",
      "Age missing values before: 106\n",
      "Age missing values after: 0\n",
      "\n",
      "Dropping 'deck' column due to excessive missing values (77%)\n",
      "\n",
      "Embarked missing values before: 2\n",
      "Embarked missing values after: 0\n",
      "==================================================\n",
      "\n",
      "STEP 3: Standardizing Formats\n",
      "\n",
      "Standardized 'embark_town' and 'who' columns:\n",
      "Unique embark_town: ['Southampton' 'Cherbourg' 'Queenstown' 'S']\n",
      "Unique who: ['man' 'woman' 'child']\n",
      "==================================================\n",
      "\n",
      "STEP 4: CORRECTING DATA TYPES\n",
      "Data types after conversion:\n",
      "survived          int64\n",
      "pclass           object\n",
      "sex              object\n",
      "age             float64\n",
      "sibsp             int64\n",
      "parch             int64\n",
      "fare            float64\n",
      "embarked         object\n",
      "class          category\n",
      "who              object\n",
      "adult_male         bool\n",
      "embark_town      object\n",
      "alive            object\n",
      "alone              bool\n",
      "dtype: object\n",
      "==================================================\n",
      "\n",
      "STEP 5: Checking for Outliers\n",
      "Age range: 0.42 to 80.0\n",
      "Fare range: 0.0 to 512.3292\n",
      "\n",
      "NOTE ABOUT FARES:\n",
      "- $0 fares might represent crew (but Titanic dataset is passengers only)\n",
      "- $512 is extremely high but plausible for luxury suites\n",
      "- We'll keep all fares as they represent real pricing tiers\n",
      "\n",
      "==================================================\n",
      "\n",
      "STEP 6: Removing Irrelevant Columns\n",
      "No irrelevant columns specified to drop.\n",
      "==================================================\n",
      "\n",
      "Final Data Quality REPORT\n",
      "Missing values:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "survived          int64\n",
      "pclass           object\n",
      "sex              object\n",
      "age             float64\n",
      "sibsp             int64\n",
      "parch             int64\n",
      "fare            float64\n",
      "embarked         object\n",
      "class          category\n",
      "who              object\n",
      "adult_male         bool\n",
      "embark_town      object\n",
      "alive            object\n",
      "alone              bool\n",
      "dtype: object\n",
      "\n",
      "Dataset shape: (784, 14)\n",
      "==================================================\n",
      "\n",
      "Cleaned dataset saved to outputs/titanic_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from cleaning_utils import (\n",
    "    load_titanic_dataset, overview, remove_duplicates, handle_missing_values,\n",
    "    fix_formatting, correct_data_types, check_outliers,\n",
    "    drop_irrelevant_columns, final_report, save_clean_data\n",
    ")\n",
    "\n",
    "data = load_titanic_dataset()\n",
    "\n",
    "overview(data)\n",
    "\n",
    "data = remove_duplicates(data)\n",
    "data = handle_missing_values(data)\n",
    "data = fix_formatting(data)\n",
    "data = correct_data_types(data)\n",
    "check_outliers(data)\n",
    "# Add if needed\n",
    "data = drop_irrelevant_columns(data, columns_to_drop=[])  \n",
    "final_report(data)\n",
    "save_clean_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
